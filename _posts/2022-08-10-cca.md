---
layout: post
title: Mathematical summary of CCA 
date: 2022-08-10 11:12:00-0400
comments: true
description: 
tags: math cca
categories: math-notes
---



**Canonical Correlation Analysis (CCA)** is a dimension reduction method that is similar to PCA, but it simultaneously reduce the dimension of **two** random vectors instead of one in PCA. Instead of trying to explain overall variance, it tries to explain the association between two random vectors, that is, the correlation between two random vectors. For example, predict cell type in a new dataset $Y$ based on the reference dataset $X$. 

The main purpose of the canonical correlation approach is the exploration of sample correlations between two sets of quantitative variables observed on the **same** experimental units (e.g same cells, different genes; or same genes, different cells ). It can reduce multiple variables into entities that can be correlated with each other.  It finds the two bases in which the correlation matrix between the variables is diagonal and correlations on the diagonal are maximized. 

## Step1:Canonical Variate Pair

Suppose we have $$p$$ cells $$\times$$ $$n$$ genes in dataset $$X$$ and $$q$$ cells $$\times $$ $$n$$ genes in dataset $$Y$$ (**both are mean-centered already**), note that row is gene, column is cell variable:

$$
X=\begin {pmatrix} x_{11} & x_{12} & ... & x_{1p} \\
                   x_{21} & x_{22} & ... & x_{2p} \\
                   . & . & ... & . \\
                   . & . & ... & . \\
                   x_{n1} & x_{n2} & ... & x_{np}  \end{pmatrix} = [\vec x_1,\vec x_2,...\vec x_p]
$$

$$
Y=\begin {pmatrix} y_{11} & y_{12} & ... & y_{1q} \\
                   y_{21} & y_{22} & ... & y_{2q} \\
                   . & . & ... & . \\
                   . & . & ... & . \\
                   y_{n1} & y_{n2} & ... & y_{nq}  \end{pmatrix} = [\vec y_1,\vec y_2,...\vec y_q]
$$

Thus, the two random vectors are: 

$$
\vec X =[\vec x_1,\vec x_2,...\vec x_p]'
$$
$$
\vec Y = [\vec y_1,\vec y_2,...\vec y_q]'
$$


Suppose $$q≤p$$ . The goal of CCA is to summarise $$\Sigma_{YX}$$ with $$q$$ numbers, which will be called **canonical correlations**. 

Define a set of linear combinations named $$u_i=\vec a_i \cdot \vec X$$ and $$ v_i=\vec b_i \cdot \vec Y$$, note that $$u_i,v_i$$ are now new random variable, not random vector. 

$$
A = [\vec a_1',\vec a_2',...,\vec a_p']' ; A^T=[\vec a_1,\vec a_2,...,\vec a_p]
$$
$$
B = [\vec b_1',\vec b_2',...,\vec b_q']'; B^T = [\vec b_1,\vec b_2,...,\vec b_q]
$$

$$
\vec U=\begin {pmatrix} u_{1}  \\
                   u_{2}  \\
                   .  \\
                   . \\
                   u_{p}  \end{pmatrix} 
 =\begin {pmatrix} a_1'\vec X  \\
                   a_2' \vec X  \\
                   .  \\
                   . \\
                   a_p'\vec X  \end{pmatrix}  =A \vec X \   \   \ \  
$$

$$
\vec V=\begin {pmatrix} v_{1}  \\
                   v_{2}  \\
                   .  \\
                   . \\
                   v_{q}  \end{pmatrix} 
 =\begin {pmatrix} b_1'\vec Y \\
                   b_2'\vec Y  \\
                   .  \\
                   . \\
                   b_q'\vec Y  \end{pmatrix} =B\vec Y
$$

$$
 U=XA^T ; V=YB^T
$$

$$U$$ is $$n \times p$$ matrix, the columns of which contains the linear recombination of random variables of dataset $$X$$. $$V$$ is $$n\times q$$ matrix, the columns of which contains the linear recombination of random variables of dataset $$Y$$. For $$i≤q$$, $$[v_i,u_i]$$ is the $$i^{th}$$ **canonical variate pair**. We hope to find linear combinations that maximize the correlations (**canonical coeffecient**) between the members of each canonical variate pair. 



## Step2: Maximize Canonical Correlation

We have correlation of $$i^{th}$$ canonical variate pair $$[v_i,u_i]$$: 

$$
Cor(v_i,u_i)=\frac{Cov(v_i,u_i)}{\sqrt{Var(v_i)Var(u_i)}}= \frac{\frac{1}{n-1}b_i^TY^TXa_i}{\sqrt{(b_i^TY^TYb_i)(a_i^TX^TXa_i)}}
$$

Two constraints: 

1. $$u_i,v_i$$ has unit length: $$||v_i||_2=||u_i||_2=1$$

2. Orthogonality: if we want to find second pair of canonical variables, these must be orthogonal or uncorrelated with the first pair. For $$i≠j,i,j≤q:$$

$$
u^T_iu_j=0 ; v^T_iv_j=0   
$$

With this notation, the goal of CCA is to find $q$ linear projections $$(a_i,b_i)$$ for $$i \in [ 1,2,...q]$$, that maximize canonical correlation of each canonical variate pair.



## Step3: Solve Cononical Correlation Vector

We can use SVD to solve this problem.

To maximize $$b_i^TY^TXa_i$$, with constraints $$b^T_iY^TYb_i=1,a^T_iX^TXa_i=1$$, 

$$
a_i=(X^TX)^{-\frac{1}{2}}u_i -> u_i^Tu_i=1
$$
$$
b_i=(Y^TY)^{-\frac{1}{2}}v_i ->v_i^Tv_i=1
$$
$$
b_i^TY^TXa_i=v^T_i(Y^TY)^{-\frac{1}{2}}Y^TX(X^TX)^{-\frac{1}{2}}u_i
$$

Apply SVD to $Z=(Y^TY)^{-\frac{1}{2}}Y^TX(X^TX)^{-\frac{1}{2}}$:

$$
Z=VDU'
$$

We find that, by doing so, the constriants are satisfied. Cause $$U^TU=I,V^TV=I$$. 

To make it easier,

$$
Y^TX=(Y^TY)^{\frac{1}{2}}VDU'(X^TX)^{\frac{1}{2}}
$$

That is to say, if we do SVD on $$Y^TX$$：

$$
Y^TX=\hat V D \hat U'
$$
$$
V = (Y^TY)^{-\frac{1}{2}}\hat V ; U=(X^TX)^{-\frac{1}{2}}\hat U
$$


We can also use Lagrange multipliers to solve this problem:

$$
\mathcal{L} = b_i^TY^TXa_i' - \frac{p_{i,1}}{2}((a_i'X)^T(a_i'X)-1) - \frac{p_{i,2}}{2}((b_i'Y)^T(b_i'Y)-1)
$$

Taking the derivatives of the loss with respect to $$b_i$$:

$$
\begin{align*}\label{1}
&\frac{\partial (b_i'Y^TXa_i)}{\partial \ b_i} = Y^TXa_i
\\
&\frac{\partial \ (\frac{p_{i,1}}{2}((a_i'X)(a_i'X)^T-1))}{\partial \ b_i} = 0
\\
&\frac{\partial \ (\frac{p_{i,2}}{2}((b_i'Y)(b_i'Y)^T-1)}{\partial \ b_i} = p_{i,2}Y^TYb_i
\end{align*}
$$

The derivatives with respect to $$a_i$$ are symmetric. Putting it all together: 

$$
\begin{align*}\label{2}
&\frac{\partial \mathcal L}{\partial a_i} = X^TYb_i -  p_{i,1}X^TXa_i = 0
\\
&\frac{\partial \mathcal L}{\partial b_i} = Y^TXa_i -  p_{i,2}Y^TYb_i = 0
\end{align*}
$$

 Prove $$p_{i,1}=p_{i,2}$$ , knowing  $$||v_i||_2^2=1 ,||u_i||_2^2=1$$: 

$$
\begin{align*}\label{3}
&a_i^T(X^TYb_i -  p_{i,1}X^TXa_i) = a_i^TX^TYb_i-p_{i,1}a_i^TX^TXa_i = a_i^TX^TYb_i-p_{i,1} = 0 
\\
&b_i^T(Y^TXa_i -  p_{i,2}Y^TYb_i)=b_i^TY^TXa_i-p_{i,2}b_i^TY^TYb_i=b_i^TY^TXa_i-p_{i,2} = 0 
\\
&=> p_{i,1}=p_{i,2}=a_i^TX^TYb_i=b_i^TY^TXa_i
\end{align*}
$$

That is to say, we need to find the maximum $$p_i$$.  

Solve Canonical Correlation Vector:

$$
\begin{align*}\label{4}
&X^TYb_i -  p_iX^TXa_i = 0  \ \ -> a_i = \frac{(X^TX)^{-1}X^TYb_i}{p_i}
\\
&Y^TXa_i -  p_{i}Y^TYb_i = 0 \ \ -> Y^TX\frac{(X^TX)^{-1}X^TYb_i}{p_i} - p_iY^TYb_i = 0
\\ 
&->p^2b_i = (Y^TY)^{-1}Y^TX(X^TX)^{-1}X^TYb_i
\end{align*}
$$

This is the standard eigenvalue problem. 

$$
((Y^TY)^{-1}Y^TX(X^TX)^{-1}X^TY-p^2I)b_i=0
$$

After solving $$b_i$$, $$a_i$$ can be easily solved. 



$$(a_i,b_i)$$ is the correlation coefficient,  $$\frac{1}{n-1}p_i$$ is the correlation between canonical variates $$v_i,u_i$$. 

$$U,V$$ columns contains $$v_i,u_i$$ , we can rank the columns by the eigenvalue (correlation). 





### Reference 

1. <https://gregorygundersen.com/blog/2018/07/17/cca/>
2. <https://www.cnblogs.com/pinard/p/6288716.html>
