<!DOCTYPE html> <html lang="en"> <head> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Mathematical summary of CCA | Gezi's TechBlog</title> <meta name="author" content="Gezi "/> <meta name="description" content="A personal technlog :). "/> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"/> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"/> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="none" id="highlight_theme_light"/> <link rel="shortcut icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>ðŸ•Š</text></svg>"> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://gezi81889.github.io/blog/2022/cca/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"/> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/">Gezi's TechBlog</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about</a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">Repositories</a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">Mathematical summary of CCA</h1> <p class="post-meta">August 10, 2022</p> <p class="post-tags"> <a href="/blog/2022"> <i class="fas fa-calendar fa-sm"></i> 2022 </a> Â  Â· Â  <a href="/blog/tag/math"> <i class="fas fa-hashtag fa-sm"></i> math</a> Â  <a href="/blog/tag/cca"> <i class="fas fa-hashtag fa-sm"></i> cca</a> Â  Â  Â· Â  <a href="/blog/category/math-notes"> <i class="fas fa-tag fa-sm"></i> math-notes</a> Â  </p> </header> <article class="post-content"> <p><strong>Canonical Correlation Analysis (CCA)</strong> is a dimension reduction method that is similar to PCA, but it simultaneously reduce the dimension of <strong>two</strong> random vectors instead of one in PCA. Instead of trying to explain overall variance, it tries to explain the association between two random vectors, that is, the correlation between two random vectors. For example, predict cell type in a new dataset \(Y\) based on the reference dataset \(X\).</p> <p>The main purpose of the canonical correlation approach is the exploration of sample correlations between two sets of quantitative variables observed on the <strong>same</strong> experimental units (e.g same cells, different genes; or same genes, different cells ). It can reduce multiple variables into entities that can be correlated with each other. It finds the two bases in which the correlation matrix between the variables is diagonal and correlations on the diagonal are maximized.</p> <h2 id="step1canonical-variate-pair">Step1:Canonical Variate Pair</h2> <p>Suppose we have \(p\) cells \(\times\) \(n\) genes in dataset \(X\) and \(q\) cells \(\times\) \(n\) genes in dataset \(Y\) (<strong>both are mean-centered already</strong>), note that row is gene, column is cell variable:</p> \[X=\begin {pmatrix} x_{11} &amp; x_{12} &amp; ... &amp; x_{1p} \\ x_{21} &amp; x_{22} &amp; ... &amp; x_{2p} \\ . &amp; . &amp; ... &amp; . \\ . &amp; . &amp; ... &amp; . \\ x_{n1} &amp; x_{n2} &amp; ... &amp; x_{np} \end{pmatrix} = [\vec x_1,\vec x_2,...\vec x_p]\] \[Y=\begin {pmatrix} y_{11} &amp; y_{12} &amp; ... &amp; y_{1q} \\ y_{21} &amp; y_{22} &amp; ... &amp; y_{2q} \\ . &amp; . &amp; ... &amp; . \\ . &amp; . &amp; ... &amp; . \\ y_{n1} &amp; y_{n2} &amp; ... &amp; y_{nq} \end{pmatrix} = [\vec y_1,\vec y_2,...\vec y_q]\] <p>Thus, the two random vectors are:</p> <p>\(\vec X =[\vec x_1,\vec x_2,...\vec x_p]'\) \(\vec Y = [\vec y_1,\vec y_2,...\vec y_q]'\)</p> <p>Suppose \(qâ‰¤p\) . The goal of CCA is to summarise \(\Sigma_{YX}\) with \(q\) numbers, which will be called <strong>canonical correlations</strong>.</p> <p>Define a set of linear combinations named \(u_i=\vec a_i \cdot \vec X\) and \(v_i=\vec b_i \cdot \vec Y\), note that \(u_i,v_i\) are now new random variable, not random vector.</p> \[A = [\vec a_1',\vec a_2',...,\vec a_p']' ; A^T=[\vec a_1,\vec a_2,...,\vec a_p]\] \[B = [\vec b_1',\vec b_2',...,\vec b_q']'; B^T = [\vec b_1,\vec b_2,...,\vec b_q]\] \[\vec U=\begin {pmatrix} u_{1} \\ u_{2} \\ . \\ . \\ u_{p} \end{pmatrix} =\begin {pmatrix} a_1'\vec X \\ a_2' \vec X \\ . \\ . \\ a_p'\vec X \end{pmatrix} =A \vec X\] \[\vec V=\begin {pmatrix} v_{1} \\ v_{2} \\ . \\ . \\ v_{q} \end{pmatrix} =\begin {pmatrix} b_1'\vec Y \\ b_2'\vec Y \\ . \\ . \\ b_q'\vec Y \end{pmatrix} =B\vec Y\] \[U=XA^T ; V=YB^T\] <p>\(U\) is \(n \times p\) matrix, the columns of which contains the linear recombination of random variables of dataset \(X\). \(V\) is \(n\times q\) matrix, the columns of which contains the linear recombination of random variables of dataset \(Y\). For \(iâ‰¤q\), \([v_i,u_i]\) is the \(i^{th}\) <strong>canonical variate pair</strong>. We hope to find linear combinations that maximize the correlations (<strong>canonical coeffecient</strong>) between the members of each canonical variate pair.</p> <h2 id="step2-maximize-canonical-correlation">Step2: Maximize Canonical Correlation</h2> <p>We have correlation of \(i^{th}\) canonical variate pair \([v_i,u_i]\):</p> \[Cor(v_i,u_i)=\frac{Cov(v_i,u_i)}{\sqrt{Var(v_i)Var(u_i)}}= \frac{b_i^TY^TXa_i}{\sqrt{(b_i^TY^TYb_i)(a_i^TX^TXa_i)}}\] <p>Two constraints:</p> <ol> <li> <p>\(u_i,v_i\) has unit length: \(b_i^TY^TYb_i=a_i^TX^TXa_i=1\)</p> </li> <li> <p>Orthogonality: if we want to find second pair of canonical variables, these must be orthogonal or uncorrelated with the first pair. For \(iâ‰ j,i,jâ‰¤q:\)</p> </li> </ol> \[u^T_iu_j=0 ; v^T_iv_j=0\] <p>With this notation, the goal of CCA is to find $q$ linear projections \((a_i,b_i)\) for \(i \in [ 1,2,...q]\), that maximize canonical correlation of each canonical variate pair.</p> <h2 id="step3-solve-cononical-correlation-vector">Step3: Solve Cononical Correlation Vector</h2> <p>We can use SVD to solve this problem.</p> <p>To maximize \(b_i^TY^TXa_i\), with constraints \(b^T_iY^TYb_i=1,a^T_iX^TXa_i=1\),</p> \[a_i=(X^TX)^{-\frac{1}{2}}\hat a_i -&gt; \hat a_i^T\hat a_i=1\] \[b_i=(Y^TY)^{-\frac{1}{2}}\hat b_i -&gt;\hat b_i^T\hat b_i=1\] \[b_i^TY^TXa_i=\hat b^T_i(Y^TY)^{-\frac{1}{2}}Y^TX(X^TX)^{-\frac{1}{2}}\hat a_i\] <p>Apply SVD to \(Z=(X^TX)^{-\frac{1}{2}}X^TY(Y^TY)^{-\frac{1}{2}}\):</p> \[Z=\hat AD\hat B'\] <p>We find that, by doing so, the constriants are satisfied. Cause \(\hat A^T\hat A=I,\hat B^T\hat B=I\).</p> <p>To make it easier,</p> \[B = (Y^TY)^{-\frac{1}{2}}\hat B\] \[A = (X^TX)^{-\frac{1}{2}}\hat A\] <p>\(B=[b_1,b_2,...b_q]\),\(A=[a_1,a_2,...a_q]\).</p> <p>We can also use Lagrange multipliers to solve this problem:</p> \[\mathcal{L} = b_i^TY^TXa_i' - \frac{p_{i,1}}{2}((a_i'X)^T(a_i'X)-1) - \frac{p_{i,2}}{2}((b_i'Y)^T(b_i'Y)-1)\] <p>Taking the derivatives of the loss with respect to \(b_i\):</p> \[\begin{align*}\label{1} &amp;\frac{\partial (b_i'Y^TXa_i)}{\partial \ b_i} = Y^TXa_i \\ &amp;\frac{\partial \ (\frac{p_{i,1}}{2}((a_i'X)(a_i'X)^T-1))}{\partial \ b_i} = 0 \\ &amp;\frac{\partial \ (\frac{p_{i,2}}{2}((b_i'Y)(b_i'Y)^T-1)}{\partial \ b_i} = p_{i,2}Y^TYb_i \end{align*}\] <p>The derivatives with respect to \(a_i\) are symmetric. Putting it all together:</p> \[\begin{align*}\label{2} &amp;\frac{\partial \mathcal L}{\partial a_i} = X^TYb_i - p_{i,1}X^TXa_i = 0 \\ &amp;\frac{\partial \mathcal L}{\partial b_i} = Y^TXa_i - p_{i,2}Y^TYb_i = 0 \end{align*}\] <table> <tbody> <tr> <td>Prove \(p_{i,1}=p_{i,2}\) , knowing $$</td> <td>Â </td> <td>v_i</td> <td>Â </td> <td>_2^2=1 ,</td> <td>Â </td> <td>u_i</td> <td>Â </td> <td>_2^2=1$$:</td> </tr> </tbody> </table> \[\begin{align*}\label{3} &amp;a_i^T(X^TYb_i - p_{i,1}X^TXa_i) = a_i^TX^TYb_i-p_{i,1}a_i^TX^TXa_i = a_i^TX^TYb_i-p_{i,1} = 0 \\ &amp;b_i^T(Y^TXa_i - p_{i,2}Y^TYb_i)=b_i^TY^TXa_i-p_{i,2}b_i^TY^TYb_i=b_i^TY^TXa_i-p_{i,2} = 0 \\ &amp;=&gt; p_{i,1}=p_{i,2}=a_i^TX^TYb_i=b_i^TY^TXa_i \end{align*}\] <p>That is to say, we need to find the maximum \(p_i\).</p> <p>Solve Canonical Correlation Vector:</p> \[\begin{align*}\label{4} &amp;X^TYb_i - p_iX^TXa_i = 0 \ \ -&gt; a_i = \frac{(X^TX)^{-1}X^TYb_i}{p_i} \\ &amp;Y^TXa_i - p_{i}Y^TYb_i = 0 \ \ -&gt; Y^TX\frac{(X^TX)^{-1}X^TYb_i}{p_i} - p_iY^TYb_i = 0 \\ &amp;-&gt;p^2b_i = (Y^TY)^{-1}Y^TX(X^TX)^{-1}X^TYb_i \end{align*}\] <p>This is the standard eigenvalue problem.</p> \[((Y^TY)^{-1}Y^TX(X^TX)^{-1}X^TY-p^2I)b_i=0\] <p>After solving \(b_i\), \(a_i\) can be easily solved.</p> <p>\((a_i,b_i)\) is the correlation coefficient, \(p_i\) is the correlation between canonical variates \(v_i,u_i\).</p> <p>\(\hat A,\hat B\) columns contains \(a_i,b_i\) , we can rank the columns by the eigenvalue (correlation).</p> <h3 id="reference">Reference</h3> <ol> <li><a href="https://gregorygundersen.com/blog/2018/07/17/cca/" target="_blank" rel="noopener noreferrer">https://gregorygundersen.com/blog/2018/07/17/cca/</a></li> <li><a href="https://www.cnblogs.com/pinard/p/6288716.html" target="_blank" rel="noopener noreferrer">https://www.cnblogs.com/pinard/p/6288716.html</a></li> </ol> </article><div id="disqus_thread"></div> <script type="text/javascript">var disqus_shortname="gezi81889-1",disqus_identifier="/blog/2022/cca",disqus_title="Mathematical summary of CCA";!function(){var e=document.createElement("script");e.type="text/javascript",e.async=!0,e.src="//"+disqus_shortname+".disqus.com/embed.js",(document.getElementsByTagName("head")[0]||document.getElementsByTagName("body")[0]).appendChild(e)}();</script> <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript" target="_blank" rel="noopener noreferrer">comments powered by Disqus.</a> </noscript> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> Â© Copyright 2023 Gezi . Powered by <a href="https://jekyllrb.com/" target="_blank" rel="noopener noreferrer">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" target="_blank" rel="noopener noreferrer">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="noopener noreferrer">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="noopener noreferrer">Unsplash</a>. Last updated: December 08, 2023. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="/assets/js/common.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> </body> </html>