<!DOCTYPE html> <html lang="en"> <head> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Mathematical summary of PCA | Gezi's TechBlog</title> <meta name="author" content="Gezi "/> <meta name="description" content="A personal technlog :). "/> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"/> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"/> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="none" id="highlight_theme_light"/> <link rel="shortcut icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üïä</text></svg>"> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://gezi81889.github.io/blog/2022/pca/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"/> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/">Gezi's TechBlog</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about</a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">Repositories</a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">Mathematical summary of PCA</h1> <p class="post-meta">June 14, 2022</p> <p class="post-tags"> <a href="/blog/2022"> <i class="fas fa-calendar fa-sm"></i> 2022 </a> ¬† ¬∑ ¬† <a href="/blog/tag/math"> <i class="fas fa-hashtag fa-sm"></i> math</a> ¬† <a href="/blog/tag/pca"> <i class="fas fa-hashtag fa-sm"></i> pca</a> ¬† ¬† ¬∑ ¬† <a href="/blog/category/math-notes"> <i class="fas fa-tag fa-sm"></i> math-notes</a> ¬† </p> </header> <article class="post-content"> <p>For the purpose of dimension reduction, we apply <strong>Principal Components Analysis (PCA)</strong> to transform data to principal components and obtain the contribution of the original vairables.</p> <h2 id="step1-the-covariance-matrix">Step1: The covariance matrix</h2> <p>For a given single cell RNA-seq <strong>count matrix \(X\in R^{n \times p}\)</strong> (\(n\) is the number of cells, \(p\) is the number of genes), the random vector \(\vec X\) is:</p> \[\vec X=[\vec x_1,\vec x_2,...\vec x_p]'\] <p><strong>The centered matrix:</strong></p> \[\hat \mu _j=\frac{1}{n}\sum_{i=1}^nx_{ij}\] \[\widetilde X=[\vec x_1-\hat \mu_1,\vec x_2-\hat \mu_2,...\vec x_p-\hat \mu_p]\] <p><strong>The covariance matrix:</strong></p> \[S=Var(\vec X)=\Sigma_{XX}=\frac{1}{n-1}\widetilde X^T\widetilde X\] <h2 id="step2-eigen-decomposition">Step2: Eigen-Decomposition</h2> <p>The <strong>covariance matrix \(S_{p\times p}\)</strong> is a symmatric matrix with diagonal predictor variance and non-diagonal inter-predictor covariance.</p> <p>For a <strong>real symmatric matrix</strong>, there exists a unique set of real eigenvalues \((\lambda_1,...\lambda_p)\), and the associated eigenvectors: \((\vec u_1,...\vec u_p)\). Such that:</p> \[\begin{align*}\label{1} Su_i &amp;=\lambda_iu_i \\ u_i^Tu_j &amp;=0, i‚â†j \ \ (orthogonal) \\ ||u_i||^2 &amp;=1 \ \ (normalized) \end{align*}\] <p>Hence, those eigenvectors \((\vec u_1,...\vec u_p)\) form an orthonormal basis for \(S\). For \(i=1,2,...p\) , both \(\lambda_i\) and \(u_i\) can be easily calculated.</p> <p><strong>Eigenvalue Spectrum:</strong></p> \[\Lambda = \begin {pmatrix} \lambda_1 &amp; 0 &amp; ... &amp; 0 \\ 0 &amp; \lambda_2 &amp; ... &amp; 0 \\ . &amp; . &amp; ... &amp; . \\ . &amp; . &amp; ... &amp; . \\ 0 &amp; 0 &amp; ... &amp; \lambda_p \end{pmatrix}\] <p><strong>Orthogonal Eigenvector Matrix:</strong></p> \[Q=\begin {pmatrix} u_{11} &amp; u_{21} &amp; ... &amp; u_{p1} \\ u_{12} &amp; u_{22} &amp; ... &amp; u_{p2} \\ . &amp; . &amp; ... &amp; . \\ . &amp; . &amp; ... &amp; . \\ u_{1p} &amp; u_{2p} &amp; ... &amp; u_{pp} \end{pmatrix} =[\vec u_1,\vec u_2,..,\vec u_p]\] \[Q^TQ=QQ^T=I \ \ &lt;=&gt; Q^{-1}=Q^T\] <p><strong>Eigen-Decomposition</strong></p> \[S=Q\Lambda Q^T\] <p><strong>Characteristics of the gram matrix S</strong></p> <ol> <li>Eigenvalues are non-negative real numbers (positive-semidefinite).</li> </ol> \[\begin{align*}\label{2} X^TXu &amp;=\lambda u \\ u^TX^TXu &amp;=u^T\lambda u \\ (Xu)^T(Xu) =\lambda u^Tu ||Xu||^2 &amp;=\lambda ||u||^2 \ =&gt; \lambda‚â•0 \end{align*}\] <ol> <li>\(X^TX\) and \(XX^T\) share the same eigenvalues.</li> </ol> \[\begin{align*}\label{3} X^TXu &amp;=\lambda u \\ XX^TXu &amp;=X\lambda u \\ XX^T(Xu) &amp;=\lambda(Xu) \\ XX^T\widetilde u &amp;=\lambda \widetilde u \end{align*}\] <ol> <li>The sum of eigenvalues (total sample variance) is equal to its trace.</li> </ol> \[Tr(X^TX)=Tr(U\Lambda U^T)=Tr(U^TU\Lambda)=Tr(\Lambda)=\sum_{i=1}^p\lambda_i\] <p><strong>SVD</strong></p> <p>We can also get the same conclusion from SVD:</p> \[\widetilde X=U\Sigma V^T\] <p>\(U_{n\times n}\) and \(V_{p\times p}\) are orthogonal matrix, \(\Sigma_{n\times p}\) is diagonal matrix.</p> <p><strong>Gene covariance matrix :</strong></p> \[X^T_{p\times n}X_{n\times p}=V_{p\times p}\Sigma^2_{p\times p}V^T_{p\times p}\] <p>For computation efficiency, we can directly do svd on \(X^TX\):</p> \[\widetilde X=U\Sigma V^T=[\vec u_1,\vec u_2,..,\vec u_p] \begin {pmatrix} \lambda_1 &amp; 0 &amp; ... &amp; 0 \\ 0 &amp; \lambda_2 &amp; ... &amp; 0 \\ . &amp; . &amp; ... &amp; . \\ . &amp; . &amp; ... &amp; . \\ 0 &amp; 0 &amp; ... &amp; \lambda_p \end{pmatrix} [\vec v_1,\vec v_2,..,\vec v_p]'\] \[S=\frac{1}{n-1}X^TX=X^TX=[\vec u_1,\vec u_2,..,\vec u_p] \begin {pmatrix} \frac{\lambda_1^2}{n-1} &amp; 0 &amp; ... &amp; 0 \\ 0 &amp; \frac{\lambda_2^2}{n-1} &amp; ... &amp; 0 \\ . &amp; . &amp; ... &amp; . \\ . &amp; . &amp; ... &amp; . \\ 0 &amp; 0 &amp; ... &amp; \frac{\lambda_p^2}{n-1} \end{pmatrix} [\vec v_1,\vec v_2,..,\vec v_p]'\] <h2 id="step3-embeddings-and-loadings">Step3: Embeddings and Loadings</h2> <p>Here we first define <strong>Principle component</strong> as the new embeddings:</p> \[\vec{PC} = [PC_1,PC_2,...,PC_p]= XV = U\Sigma\] <p>If we compute the covariance matrix of random vector \(\vec {PC}\),</p> \[Var(\vec {PC})= \frac{1}{n-1}PC^TPC=\frac{1}{n-1}(XV)^TXV=\frac{1}{n-1}\Sigma^2\] <p>We can see that:</p> <ol> <li>For \(i,j \in [1,p], i‚â†j\), \(PC_i\) and \(PC_j\) is independent. Or we can say new embeddings are orthonormal.</li> <li>\(Var(PC_i)=\lambda_i^2\) .</li> </ol> <p>If we sort columns in \(\Sigma\) based on the value of \(\lambda_i\) , then the new PC embeddings are also sorted based on their variance. This is the premise of dimension reduction.</p> <p><strong>Loadings</strong> is the coefficient of original ‚Äúcoordinate‚Äù (expression level). \(\vec v_i\) is the loadings of \(PC_i\) (a specific observation/direction of data)</p> \[[EB_1,EB_2,...EB_p]=V=[\vec v_1,\vec v_2,..,\vec v_p]\] <p><em>Example:</em> For the first pricipal component <strong><em>PC1</em></strong>, the embeddings is the linear combination of the original variables. \(x_{11},x_{12},x_{13}...x_{1p}\) are the original expression value of <em>cell 1</em>.</p> \[PC_{1,cell1} =\vec x_1 \cdot \vec v_1= v_{11}x_{11}+v_{12}x_{12}+...v_{1p}x_{1p}\] <p>\(\vec v_1\) corresponds to the first eigenvector of the covariance matrix. The elements of the \(v_{1i}\) is the loading for <em>gene i</em>.</p> <p>For the purpose of dimension reduction, we will only pick $k(k&lt;p)$ PCs.</p> \[Z=XV=U\Sigma\] \[Z_{n \times k}=X_{n\times p}V_{p\times k}=U_{n\times k}\Sigma_{k\times k}\] <p>\(Z_{n\times k}\) are low dimensional embeddings, containing \(k\) PCs.</p> <h3 id="reference">Reference</h3> <p>This blog slightly referenced the Course of Youtuber Steve Brunton.</p> <p><a href="https://www.youtube.com/watch?v=fkf4IBRSeEc" target="_blank" rel="noopener noreferrer">https://www.youtube.com/watch?v=fkf4IBRSeEc</a></p> </article><div id="disqus_thread"></div> <script type="text/javascript">var disqus_shortname="gezi81889-1",disqus_identifier="/blog/2022/pca",disqus_title="Mathematical summary of PCA";!function(){var e=document.createElement("script");e.type="text/javascript",e.async=!0,e.src="//"+disqus_shortname+".disqus.com/embed.js",(document.getElementsByTagName("head")[0]||document.getElementsByTagName("body")[0]).appendChild(e)}();</script> <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript" target="_blank" rel="noopener noreferrer">comments powered by Disqus.</a> </noscript> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> ¬© Copyright 2023 Gezi . Powered by <a href="https://jekyllrb.com/" target="_blank" rel="noopener noreferrer">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" target="_blank" rel="noopener noreferrer">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="noopener noreferrer">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="noopener noreferrer">Unsplash</a>. Last updated: December 08, 2023. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="/assets/js/common.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> </body> </html>